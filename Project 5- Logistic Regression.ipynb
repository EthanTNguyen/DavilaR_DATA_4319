{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic Regression is a Machine Learning algorithm which is used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability.\n",
    "\n",
    "### Steps of Logistic Regression procedures:\n",
    "1. Data preparation\n",
    "2. Cross-entropy (Loss function)\n",
    "3. Batch Gradient Descent function\n",
    "4. Mean error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Daily Time Spent on Site</th><th>Age</th><th>Area Income</th><th>Daily Internet Usage</th><th>Ad Topic Line</th></tr><tr><th></th><th>Float64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>String</th></tr></thead><tbody><p>1,000 rows × 10 columns (omitted printing of 5 columns)</p><tr><th>1</th><td>68.95</td><td>35</td><td>61833.9</td><td>256.09</td><td>Cloned 5thgeneration orchestration</td></tr><tr><th>2</th><td>80.23</td><td>31</td><td>68441.9</td><td>193.77</td><td>Monitored national standardization</td></tr><tr><th>3</th><td>69.47</td><td>26</td><td>59785.9</td><td>236.5</td><td>Organic bottom-line service-desk</td></tr><tr><th>4</th><td>74.15</td><td>29</td><td>54806.2</td><td>245.89</td><td>Triple-buffered reciprocal time-frame</td></tr><tr><th>5</th><td>68.37</td><td>35</td><td>73890.0</td><td>225.58</td><td>Robust logistical utilization</td></tr><tr><th>6</th><td>59.99</td><td>23</td><td>59761.6</td><td>226.74</td><td>Sharable client-driven software</td></tr><tr><th>7</th><td>88.91</td><td>33</td><td>53852.8</td><td>208.36</td><td>Enhanced dedicated support</td></tr><tr><th>8</th><td>66.0</td><td>48</td><td>24593.3</td><td>131.76</td><td>Reactive local challenge</td></tr><tr><th>9</th><td>74.53</td><td>30</td><td>68862.0</td><td>221.51</td><td>Configurable coherent function</td></tr><tr><th>10</th><td>69.88</td><td>20</td><td>55642.3</td><td>183.82</td><td>Mandatory homogeneous architecture</td></tr><tr><th>11</th><td>47.64</td><td>49</td><td>45632.5</td><td>122.02</td><td>Centralized neutral neural-net</td></tr><tr><th>12</th><td>83.07</td><td>37</td><td>62491.0</td><td>230.87</td><td>Team-oriented grid-enabled Local Area Network</td></tr><tr><th>13</th><td>69.57</td><td>48</td><td>51636.9</td><td>113.12</td><td>Centralized content-based focus group</td></tr><tr><th>14</th><td>79.52</td><td>24</td><td>51739.6</td><td>214.23</td><td>Synergistic fresh-thinking array</td></tr><tr><th>15</th><td>42.95</td><td>33</td><td>30976.0</td><td>143.56</td><td>Grass-roots coherent extranet</td></tr><tr><th>16</th><td>63.45</td><td>23</td><td>52182.2</td><td>140.64</td><td>Persistent demand-driven interface</td></tr><tr><th>17</th><td>55.39</td><td>37</td><td>23936.9</td><td>129.41</td><td>Customizable multi-tasking website</td></tr><tr><th>18</th><td>82.03</td><td>41</td><td>71511.1</td><td>187.53</td><td>Intuitive dynamic attitude</td></tr><tr><th>19</th><td>54.7</td><td>36</td><td>31087.5</td><td>118.39</td><td>Grass-roots solution-oriented conglomeration</td></tr><tr><th>20</th><td>74.58</td><td>40</td><td>23821.7</td><td>135.51</td><td>Advanced 24/7 productivity</td></tr><tr><th>21</th><td>77.22</td><td>30</td><td>64802.3</td><td>224.44</td><td>Object-based reciprocal knowledgebase</td></tr><tr><th>22</th><td>84.59</td><td>35</td><td>60015.6</td><td>226.54</td><td>Streamlined non-volatile analyzer</td></tr><tr><th>23</th><td>41.49</td><td>52</td><td>32635.7</td><td>164.83</td><td>Mandatory disintermediate utilization</td></tr><tr><th>24</th><td>87.29</td><td>36</td><td>61628.7</td><td>209.93</td><td>Future-proofed methodical protocol</td></tr><tr><th>25</th><td>41.39</td><td>41</td><td>68962.3</td><td>167.22</td><td>Exclusive neutral parallelism</td></tr><tr><th>26</th><td>78.74</td><td>28</td><td>64828.0</td><td>204.79</td><td>Public-key foreground groupware</td></tr><tr><th>27</th><td>48.53</td><td>28</td><td>38067.1</td><td>134.14</td><td>Ameliorated client-driven forecast</td></tr><tr><th>28</th><td>51.95</td><td>52</td><td>58295.8</td><td>129.23</td><td>Monitored systematic hierarchy</td></tr><tr><th>29</th><td>70.2</td><td>34</td><td>32708.9</td><td>119.2</td><td>Open-architected impactful productivity</td></tr><tr><th>30</th><td>76.02</td><td>22</td><td>46180.0</td><td>209.82</td><td>Business-focused value-added definition</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& Daily Time Spent on Site & Age & Area Income & Daily Internet Usage & Ad Topic Line & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Int64 & Float64 & Float64 & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & 68.95 & 35 & 61833.9 & 256.09 & Cloned 5thgeneration orchestration & $\\dots$ \\\\\n",
       "\t2 & 80.23 & 31 & 68441.9 & 193.77 & Monitored national standardization & $\\dots$ \\\\\n",
       "\t3 & 69.47 & 26 & 59785.9 & 236.5 & Organic bottom-line service-desk & $\\dots$ \\\\\n",
       "\t4 & 74.15 & 29 & 54806.2 & 245.89 & Triple-buffered reciprocal time-frame & $\\dots$ \\\\\n",
       "\t5 & 68.37 & 35 & 73890.0 & 225.58 & Robust logistical utilization & $\\dots$ \\\\\n",
       "\t6 & 59.99 & 23 & 59761.6 & 226.74 & Sharable client-driven software & $\\dots$ \\\\\n",
       "\t7 & 88.91 & 33 & 53852.8 & 208.36 & Enhanced dedicated support & $\\dots$ \\\\\n",
       "\t8 & 66.0 & 48 & 24593.3 & 131.76 & Reactive local challenge & $\\dots$ \\\\\n",
       "\t9 & 74.53 & 30 & 68862.0 & 221.51 & Configurable coherent function & $\\dots$ \\\\\n",
       "\t10 & 69.88 & 20 & 55642.3 & 183.82 & Mandatory homogeneous architecture & $\\dots$ \\\\\n",
       "\t11 & 47.64 & 49 & 45632.5 & 122.02 & Centralized neutral neural-net & $\\dots$ \\\\\n",
       "\t12 & 83.07 & 37 & 62491.0 & 230.87 & Team-oriented grid-enabled Local Area Network & $\\dots$ \\\\\n",
       "\t13 & 69.57 & 48 & 51636.9 & 113.12 & Centralized content-based focus group & $\\dots$ \\\\\n",
       "\t14 & 79.52 & 24 & 51739.6 & 214.23 & Synergistic fresh-thinking array & $\\dots$ \\\\\n",
       "\t15 & 42.95 & 33 & 30976.0 & 143.56 & Grass-roots coherent extranet & $\\dots$ \\\\\n",
       "\t16 & 63.45 & 23 & 52182.2 & 140.64 & Persistent demand-driven interface & $\\dots$ \\\\\n",
       "\t17 & 55.39 & 37 & 23936.9 & 129.41 & Customizable multi-tasking website & $\\dots$ \\\\\n",
       "\t18 & 82.03 & 41 & 71511.1 & 187.53 & Intuitive dynamic attitude & $\\dots$ \\\\\n",
       "\t19 & 54.7 & 36 & 31087.5 & 118.39 & Grass-roots solution-oriented conglomeration & $\\dots$ \\\\\n",
       "\t20 & 74.58 & 40 & 23821.7 & 135.51 & Advanced 24/7 productivity & $\\dots$ \\\\\n",
       "\t21 & 77.22 & 30 & 64802.3 & 224.44 & Object-based reciprocal knowledgebase & $\\dots$ \\\\\n",
       "\t22 & 84.59 & 35 & 60015.6 & 226.54 & Streamlined non-volatile analyzer & $\\dots$ \\\\\n",
       "\t23 & 41.49 & 52 & 32635.7 & 164.83 & Mandatory disintermediate utilization & $\\dots$ \\\\\n",
       "\t24 & 87.29 & 36 & 61628.7 & 209.93 & Future-proofed methodical protocol & $\\dots$ \\\\\n",
       "\t25 & 41.39 & 41 & 68962.3 & 167.22 & Exclusive neutral parallelism & $\\dots$ \\\\\n",
       "\t26 & 78.74 & 28 & 64828.0 & 204.79 & Public-key foreground groupware & $\\dots$ \\\\\n",
       "\t27 & 48.53 & 28 & 38067.1 & 134.14 & Ameliorated client-driven forecast & $\\dots$ \\\\\n",
       "\t28 & 51.95 & 52 & 58295.8 & 129.23 & Monitored systematic hierarchy & $\\dots$ \\\\\n",
       "\t29 & 70.2 & 34 & 32708.9 & 119.2 & Open-architected impactful productivity & $\\dots$ \\\\\n",
       "\t30 & 76.02 & 22 & 46180.0 & 209.82 & Business-focused value-added definition & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1000×10 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m Daily Time Spent on Site \u001b[0m\u001b[1m Age   \u001b[0m\u001b[1m Area Income \u001b[0m\u001b[1m Daily Internet Usage \u001b[0m\u001b[1m Ad\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64                  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64              \u001b[0m\u001b[90m St\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │                    68.95     35      61833.9                256.09  Cl ⋯\n",
       "    2 │                    80.23     31      68441.9                193.77  Mo\n",
       "    3 │                    69.47     26      59785.9                236.5   Or\n",
       "    4 │                    74.15     29      54806.2                245.89  Tr\n",
       "    5 │                    68.37     35      73890.0                225.58  Ro ⋯\n",
       "    6 │                    59.99     23      59761.6                226.74  Sh\n",
       "    7 │                    88.91     33      53852.8                208.36  En\n",
       "    8 │                    66.0      48      24593.3                131.76  Re\n",
       "    9 │                    74.53     30      68862.0                221.51  Co ⋯\n",
       "   10 │                    69.88     20      55642.3                183.82  Ma\n",
       "   11 │                    47.64     49      45632.5                122.02  Ce\n",
       "  ⋮   │            ⋮                ⋮         ⋮                ⋮               ⋱\n",
       "  991 │                    35.79     44      33813.1                165.62  En\n",
       "  992 │                    38.96     38      36497.2                140.67  Ve ⋯\n",
       "  993 │                    69.17     40      66193.8                123.62  Ex\n",
       "  994 │                    64.2      27      66201.0                227.63  Ph\n",
       "  995 │                    43.7      28      63127.0                173.01  Fr\n",
       "  996 │                    72.97     30      71384.6                208.58  Fu ⋯\n",
       "  997 │                    51.3      45      67782.2                134.42  Gr\n",
       "  998 │                    51.63     51      42415.7                120.37  Ex\n",
       "  999 │                    55.55     19      41920.8                187.95  Pr\n",
       " 1000 │                    45.01     26      29875.8                178.35  Vi ⋯\n",
       "\u001b[36m                                                  6 columns and 979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"internet.csv\", DataFrame)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×10 Array{Any,2}:\n",
       " 68.95  35  61833.9  256.09  …  \"3/27/2016 0:53\"   0\n",
       " 80.23  31  68441.9  193.77     \"4/4/2016 1:39\"    0\n",
       " 69.47  26  59785.9  236.5      \"3/13/2016 20:35\"  0\n",
       " 74.15  29  54806.2  245.89     \"1/10/2016 2:31\"   0\n",
       " 68.37  35  73890.0  225.58     \"6/3/2016 3:36\"    0\n",
       " 59.99  23  59761.6  226.74  …  \"5/19/2016 14:30\"  0\n",
       " 88.91  33  53852.8  208.36     \"1/28/2016 20:59\"  0\n",
       " 66.0   48  24593.3  131.76     \"3/7/2016 1:40\"    1\n",
       " 74.53  30  68862.0  221.51     \"4/18/2016 9:33\"   0\n",
       " 69.88  20  55642.3  183.82     \"7/11/2016 1:42\"   0\n",
       " 47.64  49  45632.5  122.02  …  \"3/16/2016 20:19\"  1\n",
       " 83.07  37  62491.0  230.87     \"5/8/2016 8:10\"    0\n",
       " 69.57  48  51636.9  113.12     \"6/3/2016 1:14\"    1\n",
       "  ⋮                          ⋱                     \n",
       " 89.71  48  51501.4  204.4      \"2/17/2016 7:00\"   0\n",
       " 70.96  31  55187.8  256.4      \"6/26/2016 7:01\"   0\n",
       " 35.79  44  33813.1  165.62  …  \"4/20/2016 13:36\"  1\n",
       " 38.96  38  36497.2  140.67     \"7/21/2016 16:02\"  1\n",
       " 69.17  40  66193.8  123.62     \"3/6/2016 11:36\"   1\n",
       " 64.2   27  66201.0  227.63     \"2/11/2016 23:45\"  0\n",
       " 43.7   28  63127.0  173.01     \"4/4/2016 3:57\"    1\n",
       " 72.97  30  71384.6  208.58  …  \"2/11/2016 21:49\"  1\n",
       " 51.3   45  67782.2  134.42     \"4/22/2016 2:07\"   1\n",
       " 51.63  51  42415.7  120.37     \"2/1/2016 17:24\"   1\n",
       " 55.55  19  41920.8  187.95     \"3/24/2016 2:35\"   0\n",
       " 45.01  26  29875.8  178.35     \"6/3/2016 21:43\"   1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to matrix\n",
    "convert(Matrix, data[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Array{Int64,1}:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " ⋮\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign values for x and y\n",
    "x_data = [[x[1], x[2]] for x in zip(data[:,1], data.Age)]\n",
    "y_data = [x for x in data[:,10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-entropy (Lossfunction)\n",
    "This function comes from information theory where the goal is to computes the difference between two probability distribution functions.\n",
    "\n",
    "$L_{CE}(\\hat{y}^{i},y^{i}) = -[y^{i}*log\\hat{y}^{i} + (1- y^{i})*log(1-\\hat{y}^{i})]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Loss function\n",
    "\n",
    "$Cost(w,b) = \\frac{1}{N} * \\sum\\limits _{i=1} ^{N}L_{CE}(\\hat{y}^{i},y^{i}) $ "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ(x) = 1/(1+exp(-x))\n",
    "\n",
    "function cross_entropy_loss(x, y, w, b)\n",
    "    return -y*log(σ(w'x + b)) -(1-y)*log(1 - σ(w'x+b))\n",
    "end\n",
    "\n",
    "function average_loss(features, labels, w, b)\n",
    "    N = length(features)\n",
    "    return (1/N)*sum([cross_entropy_loss(features[i], labels[i], w, b) for i = 1:N])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Gradient Descent function\n",
    "\n",
    "$\\frac{\\partial L_{CE}(w,b)}{\\partial b} = \\frac{1}{N} * \\sum\\limits _{i=1} ^{N} \\frac{\\partial L_{CE}(w,b, \\hat{x}^{i})}{\\partial b} $"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAABbCAYAAAB6SVLnAAAXX0lEQVR4Ae1dKbOryhbmXyAjIyORSCQSiUQicc8ikZGRSGTqKW7VFcjISGQkEvndWj1AQ0h2xr1JWKfq1IbQNN1fD6vXbIH/MQKMACPACCwSAWuRveZOMwKMACPACIAJAE8CRoARYAQWigATgIUOPHebEWAEGAEmADwHGAFGgBFYKAJMABY68NxtRoARYASYAPAcYAQYAUZgoQgwAVjowHO3GQFGgBFgAsBzgBFgBBiBhSLABGChA8/dZgQYAUaACQDPAUaAEWAEFooAE4CFDjx3mxFgBBgBJgA8BxgBRoARWCgCTAAWOvDcbUaAEWAEmADwHGAEGAFGYKEIMAFY6MBztxkBRoARYALAc4ARYAQYgYUiwARgoQPP3f4QBJojyjyBa1uwLAtJNWx3ezpgvw1gWxZsL0VxOKEdFuE7RuAiAkwALkLDDxiB+SBQJpIAWNEezbhZpxy+5WF75K1/DA3fX0eACcB1fPgpIzADBA7INjZswQX4yE/DJrVlDMvNcOD9fwgM3/2IABOAHyHiAozAHyNQ7+BuEmTJRoiB/LweNOiQbbBJKxb9DFDhm1sQYAJwC0pchhH4QwROuQ87LtHWO3iWBWuzxbFrT42dayMu+fjfQcIXNyPABOBmqLggI/AXCLQoYwthQZL/BkU4UgYL+X8I8fgvmsff/GgEmAB89PBx478fgQqp7WGnpD5tmQiLH4s4AgBC/u/nGKkFvh8W7uFLEGAC8BIYuRJG4E0IHDJsBgpeUggTFxBh3wBVasPT1OFNTeBqvxcBJgDfO7bcsy9AoN65sBN52tfdIaUv+QT4eYFs4yJj8x8NzQz/NthHNizH1NvMp5lMAOYzFtwSRmCEwAm5r+X/xiOtDBYK4RQV638NcOZ32dYVyuOZ98YsGsoEYBbDwI1gBCYQaPaIrHO7f1MZzOafE7jN7qcW7UyJNBOA2U0WbhAjIBFoivCig5dUBrP557znSoPjLoRl2UhHITzm0m4mAHMZCW4HI9Ah0OJUbRGuSNm7QZwfcDo7QZIymM0/O8j++KKtUjgkkvN2MN30mn3UKez/uImTn18eAWiPyKMISZYg8hx4cY5BCJX2hMN+h0hYWliwbA9pUeJwvgInAX3qR2pbHKN4pU1f26A5HVGVe+R5dR5H5rhDlJbnvz/VEX75GxBoyhRRnCCLAzhOgKwy5dgNjmWB1FMxiiwH0W7/S7LuBlUWvVz53TYN6kOJsthhb+7iPw0miepsG166ReLacDqvbOnDYZlmuqc9kng33HN+qv+Nz5dHAAZgNtjHNuygGNlRk+ZeTmxve/wdF/umROIGGHn5D1r70A0RgMMWLkWLVLbj43ro9OIG+eDkMi7D9wtH4LiFZzlIRxZH2iLJngpS9w7I2iN2gYv0DZrvtjmhEOu+97v4uQs18sBFpCkGtS9cK89sabLrjs106xyBOw/l/cIJAACys7Y2yA7mUB+QisBbv2Vid0DmbJC8YVJTr4SzkDVhTWJ0uc594+RiPOBLRkAgoA5Fg43+hCKQByXpqfxuqKRJ5TgW0uu+SmE1rIt6l+nvtGjOxHMtGvqxpiitNtK8RD7gnoC2SuDM4NDFBAAVEmFTbchdKPgWyfPsBL8RYqXeeWeyw+nJ9tiv5CxkTVqTGPW1JRL7/IRnlPiwywbHIoW/SjFT/duH4Un7mQ/LMvBsS8S0Tqx7TsyPd5sOMvY716QIq2G9LrDecQvHsrEOiwnuusbOsxG8VN57P7ZMAFAhJfFI2rMAFHyLHG2ssHi/bFxsvOTUYxAgNY4tye7PEnw0qOv+yPGzjbHyHB0pp6amSkUx53+jz1Mff+FvTbVFkoQycJq5Yb3wG0usSq6LoNdRVakMSzHwVH4XMrRh0jqdIOftCcfqXFHe1HUvvm1rVOXx6nqWCtvfs6wSBHWTod953oXd5XqXRwBOJbaRD9cLkcQh/DiCT5t9N7F6+f/UpnwZygefqEXUfV5U06I5FkgcOl0lKI2qBbfQyfJblAmd7q+cwBQ342YH1FWG0FkJ4rbyUpSmTg+AXOAyxIDxyQ+9lE5UgxPrh/bkb5otOajQdRHECSI/RBy5A05Sy/9/xRdBnc7Ha7JtjigSR8zpZLhQ4Flxx8HrGEqXw2Yoha0VoqjJGMPDmsTA9hrh7rIe8FTl2KYh1uIQKYlTvY9lBrcz3eJoJKtUWHkNxc+jMm++XRQBEMpO2xKybrn36UG3sOlGgYJv/R5bK9nqKWcfUk+Qy7/bBQKD9gA1rQpIhLVJLnqDyk19Dd/3EW4roexu9rE8uQ3kuaDAMmIhDYnRm2fg26r/QALQ7JF4Llz3Ff89bB8+WtYowhUs2zBK0GJRFYMI0Pj+0om5Si7PTaHHs9ArWyW3MBZ7Vsk1PZta944P309Q1LRDHLEVVk4bbPv42xMzVukOrBT7KkW8O6JpGqkHmCjd/XSBqHXPf+FiOQSA5JW0sY9EIVUqlVidLE5NptsyLJ1QbiP4foRtUaLIQriug5VI3NritI+xIe7Cz7AvS5T7HIlnG9wG7bn0/WkCIFlSC/JkU2MXBgiEksqwNT5kiHYGqzuYND034ySGqaeaeGMsNAEYn7IGVX7Mjd6gDJn1B7Sdxpzy+woR5FN/bRhSzbt6LrhMa7Sx6zljp1JkIbyUqZ23+CJobiJEmu+x38XwXRdrX1meNQdsfaqLfB5KlGWJYhvCMdaFFstOHk50WxQLUO9CBAFxK8bhCQdk0Q6G9HSIiV73doCdUUiuTxvJD8pAzQ3Z0R1iY43pZKeGzXvX3WIIgJzU1ihxht4k+olCwbdo8V0ymewGot4jciwMNlZIkUxnpXCQMtKOuFBE9yIcKH6uEQC9IZOFRb0LEO9PkLlhtViIiMIVczKtpHNGZZTYicRCvTah5wCYAHSj/AcXLeikahKA20QsLZq6wi6S4hDhffoIB6B0UpZrHDIIBS3vN8NQE4EaHajOAGsPyDwytR7avov12GW4V9ZEmriISkh3pYhNJ560LnjUSj2e0F/VOwTxHqdScgxaLERE4ZrpqFz3NoKBHbbeH24gcopDucsaignA2XR50w/6JDySbzcFwsEk1uUum0w2VY7ypFjMzWhjpQ2+6p1I5KTqiYvoXNsMNt1rIiAS+ZA1khNFCNTJ4iAseki22aJKo6uJwLX5Z0eQZANQxrZg782TjnikREDfkV1KL97P4gDkEFVIhf5HcwL3WIvQZkp6oQc5AHUS7kWiokVKHNmfhPWJ9+wQIYsDxz2KYyPnmnGS149R77HTppH6oNLptmSp1rSvvCYCghLBOBGiIJLJcdThi+YyiX6jq/486v2xKFWJXIeHvK4Hg4tDpgjvPad5RQB60dWgyl+5WQgHoO2Vh5uBHDSD1dUTcWrC0nC0FRIvwT//l0k5LiuUqLDagGz1TSI2owkuRnhSCazGXp8QDLZUssIOoji8qpyiGqT551BBLF3WHUT5uWLrVAQjtlm14yP/fDABoKl2UKEFtBjINqxvfhqPIzn+PUoAJNc64AKFp6t52tcy782FU3WN3PeR/ytTWI7DWZ81X60B/c1D5vd6L11YrQVdRv8s/+qxthFocagq70QxwnDIfQzfFeyFMAQZcv3k4GXD9lJoOnX2nvqB1lSY5chIPLtWVj1tOzjoTb5rEKnJ57/w40IIACBFQD0HIDdCG27ntm2wuYb1QD8GNYrIEaKhf8hc8sx5rC8prjQxcSNsdxki10ZEGTzG/66YgUJNYs8Q1Wi9wPmp5IitSye/FUJhW6zMP027afJAXLlIimmdgTjV/bFZ2hiex+/1pjAk+o/X9/tvarFlJw5ybjUZpLF/kACo+dhzAHIjtFZkHaMw0AeTgYxd49PgkHmwvR3+VebUk/NeFwetTRK72gjSHXZpgNXkHLxiBqoPW16GzlFZ6wWc5MzajYwgViTmVearek31B7oGVepgFW5xMJbs4L1Tjao64nTMOwIjuaINsrJCekO4B/ndfk8yIPm1y8UQAKBGEXtw/BhZHMIlxW3Z2943dYmtYJ0l272iclkm/ieRMgkTijE63VCZacVtN3LqVKNlglVyeaDFxJm0v6+QjCfwIcV68kSjCQApnSlFIMVLCeGufaTFHkWWIM5yVH2Xu6bKC3mqmz5hjYp+xO3nEwCas3QK7QgAiQPTkd5mciwa7BP3YSsgCh0SOB7ChMw/XYRpgS6c/emAXJldCl2ZGyJR64TWlSMC2FkiS5k2sLguFVHjpDf9OkfYWeQNOyeio+pyw0eoEgfJwK75gHQdYjcI9CVf0hs5tZ/a1tYFYt/BOtqJOEBJkmC3r898Bsz3/pcRESEnL4NI1Dv4toWVn/3INYD0hfELnc5GeNx6uyACcCskP5cTDlOTp58+7rc8DRhEQgUEb6cCgxO38CovXHI/v77iJjsovCx/UuhNvjnXH7+BANDxOEcgzJJ7fcBPJ+q5jIjUb40NL2TrumWgTuq9g5deQ1MiFOIC7tGHXEeiSoz1eb3o4Omj7w0qIf2C3fspDJ794g0TgEfAPmQi9GvPMlIlxGHEKpibVioNWXYSO5E4Z+ofPXOfDhBVIw/D3lNz6kNTv4ngVOes8lTRz/lNc2pvFgG1FVLXxircjwIKvg6pM9PQe/QBr2vG/TUp3cFQtk4iIrLIUZ44ZSw4nCFRI85HKXPHX60LhGvDP2H8/MZ7Wm/+TdzUsMJH3xvUIuZMMMmdDMr9wg0TgAdBboRX7RrrIEaWxAiinu2jZx4p7zYxcmX/n0UeVj/oDdrjDmFgyDHvbFtdFgOZ5U2v13vEkcHG3vTSvAtReIz9LpLx2VWY4reF89YOUqshsX8tQuemoT+aX762AQ/X1h5zxN4aa0+FYA8S5Fos01L0TSni8rO9tP/fxQjW9vWQJBQ5N4jvC9ls9qA9YL+f1oOZxc6uH33PrKg9YBvFvT7FfPYH10wA/gD065+cYn2vv/HU01usFW79gDIjNWXWt18/qLS8tW0vK9eg2m1R6E2MYknZlpG4vcEh3/Ymjq/6Lp0aB6aht+oDXtWAudXzy+vkZd2fV7uZALxsYLkiUN6BJ8IYPB664Pew174VFnEWe9KoS98RqTxvUGoF6cCp6TXtOzMNtS6ZYb7me1zL9yPw1QTg9tOnVrDxXxOzT5j+Znsfvb6vn3TCzxB5a9jC5LYG+ZOklTITXrsIY+IQDPvB+z5wtfTQNNSGP042cvXt6w8fxY/fe+2+cX2UXvv0qwnAa6Hi2hiBEQLtCVUew7Olw9D+TZv+8KtHbJUoaDUZZ35Ymu8YgWsIMAG4hg4/YwQuIEBhiMs8RUB28BGFTI4RRlsUhweUixe+MfVznQciWJz9tMXYVO3829IQYAKwtBF/Z3+f0gE8E774nZ0a1S1yN0vLFduVlijkF0LRIptKh28gD3Mj+uqoikdvyQTRIesy+3Enr0e/ze99JwJMAL5zXP+mV39sBdSeDthvQ+HmLzy1degChUZzLDsvVifa4SGRjUjzZ2HlaTNE6fPhqIDx9V6an650qONXjURnBUShPkYde9U3uJ7FIcAE4DeGvD0ij5QdtOfAi3N0VoT0/bZBUx9QloVwQf+NJn3vN3QyEAubqSweRKTsy2E57sblVCAYRJS9u4YbXtAhIUaxq25481uLNGWKKE6QxQEcJ0BmRmyj9UTpVMs98rw6C+nwrZg80i8mAI+g9tQ7DfYxxUcves/RtsGpiIRH5NC7+KkPLfNl4X1qq6Qq517AIvDYZNylB+HSiUTe6AimQw3r4GUPtvR7Xztu4VkOUh0JjggAiSNvyevxvajc1DMmADfB9OJCYtPYwIwKoXMHZHoSv/iTS6lO2On7GbJQmuZ1OUcEAKbN/usQOR1KVEYWqdfVTBHIldzfjMZ5yweIM9GhyG8p/9FlVB4PI8Wp9tfQwRg/untvbDwTgDeCe7nqColloY+8qSMinieYuVwHP5lCgHIgEBelk4BbxqYAEaJ7mB9hqo7Z/KYDwdnuhbj7l1sqQg2bXOblol/xRAae6zk+mQvjsWBvXwHIjZ1gAnAjUK8tJlPY2Tppq46IOJUw5rUf/vLaSCHrQnJRKh8Che3WOlMK0a1iwM8fCB3M7hG5v46dPx14cP59v7+FMlGSTpqjxv6rotvej8ktbzABuAWlZ8ucSmwjH64XIolD+HEkMhBZKmxzz67WOJJjEQXDErHGf8hk9Gy7vu19SlRihNjVXrM65R6J2W7Lr/vXwFC6T5li8H5nL5nMhOaPTAz01315x/d1knnyv6CcBSHiiJLKqBO/CtBH6SprEbRxJfRrKy89Sw7zjtZ9Up1MAN48WiTDdW0K3KWtEWQiCHKf11mXJLvqwPd9ka2Lgggct56YtJOWLG9u86dWL8QepoJX53zebHEUWaOM9J8z7iSl5rRFKsg1/FgmJdLJia7+NRKyUGY4U8c04+7e2bQaRbgSOa07zk5HZLWkdZfkBtZiPYXbShhbUDIXgakpErzzy99YnAnAO0dVJHoxc6nKj+lMSYGZupFS4ul8plRM2dT/mE/1ne3/qLolYR1aUSnloGUhKQpEVigThs+5X1ruLwjAEzFm7AfyQswZF9U2ydWNCLlOUSkC8PVjPkibqsuwWGgwykwABnC89kaLIOKyNSrWmapcmfhanV7sIIcWVVNheYqxwFYMBnRXLykss5b/9wU7ZTBtqCJVZv9sdleds9cTG78mHA5xPV/2T+UrttzdYK3QYUmc7kmHpnNxOyODClWGxELmavwyhO7uDhOAuyG79QV9Ehk5HWmxhDqJSPPPDZLKnJbKmWmcD/jWTy+xHJnWbkaLXuCglcGm1dUcAWpRpt5T4bQHobiT/fc5QCmfCy061aMo06/aIhyH1qf5nXyIShF3aAux0e5N5rq6LZ/2lwnA20bshCKgk1xvmkafkk49moVV3IChuKQyIuCX7XVp897WxC+qWGwCpvzf6JvkxD7I/NNoO18aCBzkSb83n6Z0DHtElDNZHaikPm041tKXwkGUH/n0b8BJl0wARoC88lZuPD0HICeiYdanzD/15KVvi4BiqxDbw3viyb+yf/Ooq8ExT4SinaxAsv3x/ORLXNfHmH/OA9VZtkKJgHoOQIXI6JzkFLdnJ+ikrqRTWbnCuMLksWfZvz9oFBOAt4JOieI9OH6MLA7h+hG2JWWRUv9aeu7DWUfYURygJEGy26PmvV8jxH8ZgQECFOIhcDyECZl/ugjTAn0ahgZVFsJd+0iLPYosQZzlqIwlN6iMb5gD4DnACDACjMBSEWAOYKkjz/1mBBiBxSPABGDxU4ABmAUCNXkxW1jp8CDPNIo8z0MXQc6yj2dgXMK7TACWMMrcx/kjoBLNDJyX7m11e0SRJoiCjfAiH1jL3FsXl18EAkwAFjHM3MlFIaC8yJkALGrUH+osE4CHYOOXGIEZI8AEYMaDM6+mMQGY13hwa5aGQHOUqUAzMmtMe/v1Z3BgAvAMeot6lwnAooabOztLBEgBPIhV1KJpmpv/nzk4MQGY5TDPsVFMAOY4KtymZSGgApV1kUzVBk4hw2/5r9JK9JgxAeix4KurCDABuAoPP2QE3o+ADGa2uTvt48WWMQG4CA0/GCLABGCIB98xAr+MAKWxtGCNAgI+1QgmAE/Bt6SXmQAsabS5r/NDQAcEHEQyZR3A/AbqO1vEBOA7x5V79SEI9PHrT0BT40QaXdYBfMjofX4zmQB8/hhyDz4YASn/d7GtSqTxDi/JV1Il7An8wXPiN5vOBOA30eZvMQIjBE5FiJW9hhtt8XwKiAbHskDq2YIA2F6KoprIjzBqA98uFwEmAMsde+45I8AILBwBJgALnwDcfUaAEVguAkwAljv23HNGgBFYOAJMABY+Abj7jAAjsFwEmAAsd+y554wAI7BwBJgALHwCcPcZAUZguQgwAVju2HPPGQFGYOEIMAFY+ATg7jMCjMByEWACsNyx554zAozAwhFgArDwCcDdZwQYgeUi8B801AlA+6H85AAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features, labels, w, b, α)\n",
    "    \n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    \n",
    "    N = length(features)\n",
    "    \n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i]+b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i]+b) - labels[i])\n",
    "    end\n",
    "    \n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    \n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial cost is: 0.6931471805599448\n",
      "The new cost is: 0.68929742452507\n",
      "The new cost is: 0.685902148554632\n",
      "The new cost is: 0.682845301153201\n",
      "The new cost is: 0.6800414995518517\n"
     ]
    }
   ],
   "source": [
    "w = [0.0, 0.0]\n",
    "b = 0.0\n",
    "println(\"The initial cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_batch_gradient_descent(features, labels, w, b, α, epochs)\n",
    "    \n",
    "    for i = 1:epochs\n",
    "        \n",
    "        w, b = batch_gradient_descent(features, labels, w, b, α)\n",
    "        \n",
    "        if i == 1\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end        \n",
    "        \n",
    "        if i == 10000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "\n",
    "        if i == 100000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end  \n",
    "    end\n",
    "    \n",
    "    return w,b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.6663716486734741\n",
      "Epoch 100 with loss: 0.3304944524857512\n",
      "Epoch 1000 with loss: 0.3082781858351418\n",
      "Epoch 10000 with loss: 0.3066952740428512\n",
      "Epoch 100000 with loss: 0.293757141589279\n",
      "Epoch 100000 with loss: 0.293757141589279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.12446326645856375, 0.19863923078348777], 1.2123632358592102)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [0.0, 0.0]\n",
    "b = 0.0\n",
    "\n",
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: NaN\n",
      "Epoch 100 with loss: 0.44026001501689976\n",
      "Epoch 1000 with loss: 0.287222512108937\n",
      "Epoch 10000 with loss: 0.28640423203607124\n",
      "Epoch 100000 with loss: 0.2796755545865263\n",
      "Epoch 100000 with loss: 0.2796755545865263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1367734667551638, 0.18051984307320526], 2.713377601038628)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = randn(2)\n",
    "b = randn(1)[1]\n",
    "\n",
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.279675492180302\n",
      "Epoch 100 with loss: 0.2796693151527702\n",
      "Epoch 1000 with loss: 0.27961326815659965\n",
      "Epoch 10000 with loss: 0.27906333001045586\n",
      "Epoch 100000 with loss: 0.27448224573627905\n",
      "Epoch 100000 with loss: 0.27448224573627905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.14326192319833103, 0.17300053648367972], 3.4328939167412384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2744822029066414\n",
      "Epoch 100 with loss: 0.2744779635529041\n",
      "Epoch 1000 with loss: 0.2744394947498569\n",
      "Epoch 10000 with loss: 0.2740617252972232\n",
      "Epoch 100000 with loss: 0.2708905627848586\n",
      "Epoch 100000 with loss: 0.2708905627848586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1489324445456075, 0.16729043428188786], 4.031337779861745)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2708905329121075\n",
      "Epoch 100 with loss: 0.27088757603118907\n",
      "Epoch 1000 with loss: 0.2708607425902135\n",
      "Epoch 10000 with loss: 0.27059703411499403\n",
      "Epoch 100000 with loss: 0.26836777989604754\n",
      "Epoch 100000 with loss: 0.26836777989604754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1538680679083046, 0.1628671615468941], 4.532943338968981)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2683677587534985\n",
      "Epoch 100 with loss: 0.26836566599581146\n",
      "Epoch 1000 with loss: 0.26834667309564014\n",
      "Epoch 10000 with loss: 0.26815989244620375\n",
      "Epoch 100000 with loss: 0.2665711351819897\n",
      "Epoch 100000 with loss: 0.2665711351819897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.15815751892688973, 0.15938002994837308], 4.956287736032649)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.26657112002446437\n",
      "Epoch 100 with loss: 0.26656961967472415\n",
      "Epoch 1000 with loss: 0.26655600237973576\n",
      "Epoch 10000 with loss: 0.26642200792426746\n",
      "Epoch 100000 with loss: 0.26527608970416344\n",
      "Epoch 100000 with loss: 0.26527608970416344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1618849515164855, 0.15658868922940739], 5.315738002246925)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2652760787153867\n",
      "Epoch 100 with loss: 0.26527499099867\n",
      "Epoch 1000 with loss: 0.2652651182834484\n",
      "Epoch 10000 with loss: 0.2651679211865382\n",
      "Epoch 100000 with loss: 0.2643328129928623\n",
      "Epoch 100000 with loss: 0.2643328129928623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1651260397063733, 0.1543247758130958], 5.622529837741352)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.26433280494921957\n",
      "Epoch 100 with loss: 0.2643320087510649\n",
      "Epoch 1000 with loss: 0.2643247816967789\n",
      "Epoch 10000 with loss: 0.2642536000532785\n",
      "Epoch 100000 with loss: 0.263639555439636\n",
      "Epoch 100000 with loss: 0.263639555439636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.16794706706386583, 0.15246780826940348], 5.885553512642443)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mean error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(x, y, w, b)\n",
    "    if σ(w'x+b) >= 0.5\n",
    "        return 1\n",
    "    else\n",
    "        return 0       \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error: 0.098\n"
     ]
    }
   ],
   "source": [
    "mean_error = 0.0\n",
    "for i = 1:length(x_data)\n",
    "    mean_error += (predict(x_data[i], y_data[i], w, b) - y_data[i])^2\n",
    "end\n",
    "\n",
    "println(\"The average error: \", mean_error/length(x_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
