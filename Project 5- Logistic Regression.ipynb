{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic Regression is a Machine Learning algorithm which is used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability.\n",
    "\n",
    "### Steps of Logistic Regression procedures:\n",
    "1. Data preparation\n",
    "2. Cross-entropy (Loss function)\n",
    "3. Batch Gradient Descent function\n",
    "4. Mean error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Daily Time Spent on Site</th><th>Age</th><th>Area Income</th><th>Daily Internet Usage</th><th>Ad Topic Line</th></tr><tr><th></th><th>Float64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>String</th></tr></thead><tbody><p>1,000 rows × 10 columns (omitted printing of 5 columns)</p><tr><th>1</th><td>68.95</td><td>35</td><td>61833.9</td><td>256.09</td><td>Cloned 5thgeneration orchestration</td></tr><tr><th>2</th><td>80.23</td><td>31</td><td>68441.9</td><td>193.77</td><td>Monitored national standardization</td></tr><tr><th>3</th><td>69.47</td><td>26</td><td>59785.9</td><td>236.5</td><td>Organic bottom-line service-desk</td></tr><tr><th>4</th><td>74.15</td><td>29</td><td>54806.2</td><td>245.89</td><td>Triple-buffered reciprocal time-frame</td></tr><tr><th>5</th><td>68.37</td><td>35</td><td>73890.0</td><td>225.58</td><td>Robust logistical utilization</td></tr><tr><th>6</th><td>59.99</td><td>23</td><td>59761.6</td><td>226.74</td><td>Sharable client-driven software</td></tr><tr><th>7</th><td>88.91</td><td>33</td><td>53852.8</td><td>208.36</td><td>Enhanced dedicated support</td></tr><tr><th>8</th><td>66.0</td><td>48</td><td>24593.3</td><td>131.76</td><td>Reactive local challenge</td></tr><tr><th>9</th><td>74.53</td><td>30</td><td>68862.0</td><td>221.51</td><td>Configurable coherent function</td></tr><tr><th>10</th><td>69.88</td><td>20</td><td>55642.3</td><td>183.82</td><td>Mandatory homogeneous architecture</td></tr><tr><th>11</th><td>47.64</td><td>49</td><td>45632.5</td><td>122.02</td><td>Centralized neutral neural-net</td></tr><tr><th>12</th><td>83.07</td><td>37</td><td>62491.0</td><td>230.87</td><td>Team-oriented grid-enabled Local Area Network</td></tr><tr><th>13</th><td>69.57</td><td>48</td><td>51636.9</td><td>113.12</td><td>Centralized content-based focus group</td></tr><tr><th>14</th><td>79.52</td><td>24</td><td>51739.6</td><td>214.23</td><td>Synergistic fresh-thinking array</td></tr><tr><th>15</th><td>42.95</td><td>33</td><td>30976.0</td><td>143.56</td><td>Grass-roots coherent extranet</td></tr><tr><th>16</th><td>63.45</td><td>23</td><td>52182.2</td><td>140.64</td><td>Persistent demand-driven interface</td></tr><tr><th>17</th><td>55.39</td><td>37</td><td>23936.9</td><td>129.41</td><td>Customizable multi-tasking website</td></tr><tr><th>18</th><td>82.03</td><td>41</td><td>71511.1</td><td>187.53</td><td>Intuitive dynamic attitude</td></tr><tr><th>19</th><td>54.7</td><td>36</td><td>31087.5</td><td>118.39</td><td>Grass-roots solution-oriented conglomeration</td></tr><tr><th>20</th><td>74.58</td><td>40</td><td>23821.7</td><td>135.51</td><td>Advanced 24/7 productivity</td></tr><tr><th>21</th><td>77.22</td><td>30</td><td>64802.3</td><td>224.44</td><td>Object-based reciprocal knowledgebase</td></tr><tr><th>22</th><td>84.59</td><td>35</td><td>60015.6</td><td>226.54</td><td>Streamlined non-volatile analyzer</td></tr><tr><th>23</th><td>41.49</td><td>52</td><td>32635.7</td><td>164.83</td><td>Mandatory disintermediate utilization</td></tr><tr><th>24</th><td>87.29</td><td>36</td><td>61628.7</td><td>209.93</td><td>Future-proofed methodical protocol</td></tr><tr><th>25</th><td>41.39</td><td>41</td><td>68962.3</td><td>167.22</td><td>Exclusive neutral parallelism</td></tr><tr><th>26</th><td>78.74</td><td>28</td><td>64828.0</td><td>204.79</td><td>Public-key foreground groupware</td></tr><tr><th>27</th><td>48.53</td><td>28</td><td>38067.1</td><td>134.14</td><td>Ameliorated client-driven forecast</td></tr><tr><th>28</th><td>51.95</td><td>52</td><td>58295.8</td><td>129.23</td><td>Monitored systematic hierarchy</td></tr><tr><th>29</th><td>70.2</td><td>34</td><td>32708.9</td><td>119.2</td><td>Open-architected impactful productivity</td></tr><tr><th>30</th><td>76.02</td><td>22</td><td>46180.0</td><td>209.82</td><td>Business-focused value-added definition</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& Daily Time Spent on Site & Age & Area Income & Daily Internet Usage & Ad Topic Line & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Int64 & Float64 & Float64 & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & 68.95 & 35 & 61833.9 & 256.09 & Cloned 5thgeneration orchestration & $\\dots$ \\\\\n",
       "\t2 & 80.23 & 31 & 68441.9 & 193.77 & Monitored national standardization & $\\dots$ \\\\\n",
       "\t3 & 69.47 & 26 & 59785.9 & 236.5 & Organic bottom-line service-desk & $\\dots$ \\\\\n",
       "\t4 & 74.15 & 29 & 54806.2 & 245.89 & Triple-buffered reciprocal time-frame & $\\dots$ \\\\\n",
       "\t5 & 68.37 & 35 & 73890.0 & 225.58 & Robust logistical utilization & $\\dots$ \\\\\n",
       "\t6 & 59.99 & 23 & 59761.6 & 226.74 & Sharable client-driven software & $\\dots$ \\\\\n",
       "\t7 & 88.91 & 33 & 53852.8 & 208.36 & Enhanced dedicated support & $\\dots$ \\\\\n",
       "\t8 & 66.0 & 48 & 24593.3 & 131.76 & Reactive local challenge & $\\dots$ \\\\\n",
       "\t9 & 74.53 & 30 & 68862.0 & 221.51 & Configurable coherent function & $\\dots$ \\\\\n",
       "\t10 & 69.88 & 20 & 55642.3 & 183.82 & Mandatory homogeneous architecture & $\\dots$ \\\\\n",
       "\t11 & 47.64 & 49 & 45632.5 & 122.02 & Centralized neutral neural-net & $\\dots$ \\\\\n",
       "\t12 & 83.07 & 37 & 62491.0 & 230.87 & Team-oriented grid-enabled Local Area Network & $\\dots$ \\\\\n",
       "\t13 & 69.57 & 48 & 51636.9 & 113.12 & Centralized content-based focus group & $\\dots$ \\\\\n",
       "\t14 & 79.52 & 24 & 51739.6 & 214.23 & Synergistic fresh-thinking array & $\\dots$ \\\\\n",
       "\t15 & 42.95 & 33 & 30976.0 & 143.56 & Grass-roots coherent extranet & $\\dots$ \\\\\n",
       "\t16 & 63.45 & 23 & 52182.2 & 140.64 & Persistent demand-driven interface & $\\dots$ \\\\\n",
       "\t17 & 55.39 & 37 & 23936.9 & 129.41 & Customizable multi-tasking website & $\\dots$ \\\\\n",
       "\t18 & 82.03 & 41 & 71511.1 & 187.53 & Intuitive dynamic attitude & $\\dots$ \\\\\n",
       "\t19 & 54.7 & 36 & 31087.5 & 118.39 & Grass-roots solution-oriented conglomeration & $\\dots$ \\\\\n",
       "\t20 & 74.58 & 40 & 23821.7 & 135.51 & Advanced 24/7 productivity & $\\dots$ \\\\\n",
       "\t21 & 77.22 & 30 & 64802.3 & 224.44 & Object-based reciprocal knowledgebase & $\\dots$ \\\\\n",
       "\t22 & 84.59 & 35 & 60015.6 & 226.54 & Streamlined non-volatile analyzer & $\\dots$ \\\\\n",
       "\t23 & 41.49 & 52 & 32635.7 & 164.83 & Mandatory disintermediate utilization & $\\dots$ \\\\\n",
       "\t24 & 87.29 & 36 & 61628.7 & 209.93 & Future-proofed methodical protocol & $\\dots$ \\\\\n",
       "\t25 & 41.39 & 41 & 68962.3 & 167.22 & Exclusive neutral parallelism & $\\dots$ \\\\\n",
       "\t26 & 78.74 & 28 & 64828.0 & 204.79 & Public-key foreground groupware & $\\dots$ \\\\\n",
       "\t27 & 48.53 & 28 & 38067.1 & 134.14 & Ameliorated client-driven forecast & $\\dots$ \\\\\n",
       "\t28 & 51.95 & 52 & 58295.8 & 129.23 & Monitored systematic hierarchy & $\\dots$ \\\\\n",
       "\t29 & 70.2 & 34 & 32708.9 & 119.2 & Open-architected impactful productivity & $\\dots$ \\\\\n",
       "\t30 & 76.02 & 22 & 46180.0 & 209.82 & Business-focused value-added definition & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1000×10 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m Daily Time Spent on Site \u001b[0m\u001b[1m Age   \u001b[0m\u001b[1m Area Income \u001b[0m\u001b[1m Daily Internet Usage \u001b[0m\u001b[1m Ad\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64                  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64              \u001b[0m\u001b[90m St\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │                    68.95     35      61833.9                256.09  Cl ⋯\n",
       "    2 │                    80.23     31      68441.9                193.77  Mo\n",
       "    3 │                    69.47     26      59785.9                236.5   Or\n",
       "    4 │                    74.15     29      54806.2                245.89  Tr\n",
       "    5 │                    68.37     35      73890.0                225.58  Ro ⋯\n",
       "    6 │                    59.99     23      59761.6                226.74  Sh\n",
       "    7 │                    88.91     33      53852.8                208.36  En\n",
       "    8 │                    66.0      48      24593.3                131.76  Re\n",
       "    9 │                    74.53     30      68862.0                221.51  Co ⋯\n",
       "   10 │                    69.88     20      55642.3                183.82  Ma\n",
       "   11 │                    47.64     49      45632.5                122.02  Ce\n",
       "  ⋮   │            ⋮                ⋮         ⋮                ⋮               ⋱\n",
       "  991 │                    35.79     44      33813.1                165.62  En\n",
       "  992 │                    38.96     38      36497.2                140.67  Ve ⋯\n",
       "  993 │                    69.17     40      66193.8                123.62  Ex\n",
       "  994 │                    64.2      27      66201.0                227.63  Ph\n",
       "  995 │                    43.7      28      63127.0                173.01  Fr\n",
       "  996 │                    72.97     30      71384.6                208.58  Fu ⋯\n",
       "  997 │                    51.3      45      67782.2                134.42  Gr\n",
       "  998 │                    51.63     51      42415.7                120.37  Ex\n",
       "  999 │                    55.55     19      41920.8                187.95  Pr\n",
       " 1000 │                    45.01     26      29875.8                178.35  Vi ⋯\n",
       "\u001b[36m                                                  6 columns and 979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"internet.csv\", DataFrame)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×10 Array{Any,2}:\n",
       " 68.95  35  61833.9  256.09  …  \"3/27/2016 0:53\"   0\n",
       " 80.23  31  68441.9  193.77     \"4/4/2016 1:39\"    0\n",
       " 69.47  26  59785.9  236.5      \"3/13/2016 20:35\"  0\n",
       " 74.15  29  54806.2  245.89     \"1/10/2016 2:31\"   0\n",
       " 68.37  35  73890.0  225.58     \"6/3/2016 3:36\"    0\n",
       " 59.99  23  59761.6  226.74  …  \"5/19/2016 14:30\"  0\n",
       " 88.91  33  53852.8  208.36     \"1/28/2016 20:59\"  0\n",
       " 66.0   48  24593.3  131.76     \"3/7/2016 1:40\"    1\n",
       " 74.53  30  68862.0  221.51     \"4/18/2016 9:33\"   0\n",
       " 69.88  20  55642.3  183.82     \"7/11/2016 1:42\"   0\n",
       " 47.64  49  45632.5  122.02  …  \"3/16/2016 20:19\"  1\n",
       " 83.07  37  62491.0  230.87     \"5/8/2016 8:10\"    0\n",
       " 69.57  48  51636.9  113.12     \"6/3/2016 1:14\"    1\n",
       "  ⋮                          ⋱                     \n",
       " 89.71  48  51501.4  204.4      \"2/17/2016 7:00\"   0\n",
       " 70.96  31  55187.8  256.4      \"6/26/2016 7:01\"   0\n",
       " 35.79  44  33813.1  165.62  …  \"4/20/2016 13:36\"  1\n",
       " 38.96  38  36497.2  140.67     \"7/21/2016 16:02\"  1\n",
       " 69.17  40  66193.8  123.62     \"3/6/2016 11:36\"   1\n",
       " 64.2   27  66201.0  227.63     \"2/11/2016 23:45\"  0\n",
       " 43.7   28  63127.0  173.01     \"4/4/2016 3:57\"    1\n",
       " 72.97  30  71384.6  208.58  …  \"2/11/2016 21:49\"  1\n",
       " 51.3   45  67782.2  134.42     \"4/22/2016 2:07\"   1\n",
       " 51.63  51  42415.7  120.37     \"2/1/2016 17:24\"   1\n",
       " 55.55  19  41920.8  187.95     \"3/24/2016 2:35\"   0\n",
       " 45.01  26  29875.8  178.35     \"6/3/2016 21:43\"   1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to matrix\n",
    "convert(Matrix, data[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Array{Int64,1}:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " ⋮\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign values for x and y\n",
    "x_data = [[x[1], x[2]] for x in zip(data[:,1], data.Age)]\n",
    "y_data = [x for x in data[:,10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-entropy (Lossfunction)\n",
    "This function comes from information theory where the goal is to computes the difference between two probability distribution functions.\n",
    "\n",
    "$L_{CE}(\\hat{y}^{i},y^{i}) = -[y^{i}*log\\hat{y}^{i} + (1- y^{i})*log(1-\\hat{y}^{i})]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Loss function\n",
    "\n",
    "$Cost(w,b) = \\frac{1}{N} * \\sum\\limits _{i=1} ^{N}L_{CE}(\\hat{y}^{i},y^{i}) $ "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ(x) = 1/(1+exp(-x))\n",
    "\n",
    "function cross_entropy_loss(x, y, w, b)\n",
    "    return -y*log(σ(w'x + b)) -(1-y)*log(1 - σ(w'x+b))\n",
    "end\n",
    "\n",
    "function average_loss(features, labels, w, b)\n",
    "    N = length(features)\n",
    "    return (1/N)*sum([cross_entropy_loss(features[i], labels[i], w, b) for i = 1:N])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Gradient Descent function\n",
    "\n",
    "$\\frac{\\partial L_{CE}(w,b)}{\\partial b} = \\frac{1}{N} * \\sum\\limits _{i=1} ^{N} \\frac{\\partial L_{CE}(w,b, \\hat{x}^{i})}{\\partial b} $"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features, labels, w, b, α)\n",
    "    \n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    \n",
    "    N = length(features)\n",
    "    \n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i]+b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i]+b) - labels[i])\n",
    "    end\n",
    "    \n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    \n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial cost is: 0.6931471805599448\n",
      "The new cost is: 0.68929742452507\n",
      "The new cost is: 0.685902148554632\n",
      "The new cost is: 0.682845301153201\n",
      "The new cost is: 0.6800414995518517\n"
     ]
    }
   ],
   "source": [
    "w = [0.0, 0.0]\n",
    "b = 0.0\n",
    "println(\"The initial cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_batch_gradient_descent(features, labels, w, b, α, epochs)\n",
    "    \n",
    "    for i = 1:epochs\n",
    "        \n",
    "        w, b = batch_gradient_descent(features, labels, w, b, α)\n",
    "        \n",
    "        if i == 1\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end        \n",
    "        \n",
    "        if i == 10000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "\n",
    "        if i == 100000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end  \n",
    "    end\n",
    "    \n",
    "    return w,b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.6663716486734741\n",
      "Epoch 100 with loss: 0.3304944524857512\n",
      "Epoch 1000 with loss: 0.3082781858351418\n",
      "Epoch 10000 with loss: 0.3066952740428512\n",
      "Epoch 100000 with loss: 0.293757141589279\n",
      "Epoch 100000 with loss: 0.293757141589279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.12446326645856375, 0.19863923078348777], 1.2123632358592102)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [0.0, 0.0]\n",
    "b = 0.0\n",
    "\n",
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: NaN\n",
      "Epoch 100 with loss: 0.44026001501689976\n",
      "Epoch 1000 with loss: 0.287222512108937\n",
      "Epoch 10000 with loss: 0.28640423203607124\n",
      "Epoch 100000 with loss: 0.2796755545865263\n",
      "Epoch 100000 with loss: 0.2796755545865263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1367734667551638, 0.18051984307320526], 2.713377601038628)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = randn(2)\n",
    "b = randn(1)[1]\n",
    "\n",
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.279675492180302\n",
      "Epoch 100 with loss: 0.2796693151527702\n",
      "Epoch 1000 with loss: 0.27961326815659965\n",
      "Epoch 10000 with loss: 0.27906333001045586\n",
      "Epoch 100000 with loss: 0.27448224573627905\n",
      "Epoch 100000 with loss: 0.27448224573627905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.14326192319833103, 0.17300053648367972], 3.4328939167412384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2744822029066414\n",
      "Epoch 100 with loss: 0.2744779635529041\n",
      "Epoch 1000 with loss: 0.2744394947498569\n",
      "Epoch 10000 with loss: 0.2740617252972232\n",
      "Epoch 100000 with loss: 0.2708905627848586\n",
      "Epoch 100000 with loss: 0.2708905627848586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1489324445456075, 0.16729043428188786], 4.031337779861745)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2708905329121075\n",
      "Epoch 100 with loss: 0.27088757603118907\n",
      "Epoch 1000 with loss: 0.2708607425902135\n",
      "Epoch 10000 with loss: 0.27059703411499403\n",
      "Epoch 100000 with loss: 0.26836777989604754\n",
      "Epoch 100000 with loss: 0.26836777989604754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1538680679083046, 0.1628671615468941], 4.532943338968981)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2683677587534985\n",
      "Epoch 100 with loss: 0.26836566599581146\n",
      "Epoch 1000 with loss: 0.26834667309564014\n",
      "Epoch 10000 with loss: 0.26815989244620375\n",
      "Epoch 100000 with loss: 0.2665711351819897\n",
      "Epoch 100000 with loss: 0.2665711351819897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.15815751892688973, 0.15938002994837308], 4.956287736032649)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.26657112002446437\n",
      "Epoch 100 with loss: 0.26656961967472415\n",
      "Epoch 1000 with loss: 0.26655600237973576\n",
      "Epoch 10000 with loss: 0.26642200792426746\n",
      "Epoch 100000 with loss: 0.26527608970416344\n",
      "Epoch 100000 with loss: 0.26527608970416344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1618849515164855, 0.15658868922940739], 5.315738002246925)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2652760787153867\n",
      "Epoch 100 with loss: 0.26527499099867\n",
      "Epoch 1000 with loss: 0.2652651182834484\n",
      "Epoch 10000 with loss: 0.2651679211865382\n",
      "Epoch 100000 with loss: 0.2643328129928623\n",
      "Epoch 100000 with loss: 0.2643328129928623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1651260397063733, 0.1543247758130958], 5.622529837741352)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.26433280494921957\n",
      "Epoch 100 with loss: 0.2643320087510649\n",
      "Epoch 1000 with loss: 0.2643247816967789\n",
      "Epoch 10000 with loss: 0.2642536000532785\n",
      "Epoch 100000 with loss: 0.263639555439636\n",
      "Epoch 100000 with loss: 0.263639555439636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.16794706706386583, 0.15246780826940348], 5.885553512642443)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mean error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(x, y, w, b)\n",
    "    if σ(w'x+b) >= 0.5\n",
    "        return 1\n",
    "    else\n",
    "        return 0       \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error: 0.098\n"
     ]
    }
   ],
   "source": [
    "mean_error = 0.0\n",
    "for i = 1:length(x_data)\n",
    "    mean_error += (predict(x_data[i], y_data[i], w, b) - y_data[i])^2\n",
    "end\n",
    "\n",
    "println(\"The average error: \", mean_error/length(x_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
