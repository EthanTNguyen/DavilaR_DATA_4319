{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic Regression is a Machine Learning algorithm which is used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability.\n",
    "\n",
    "### Steps of Logistic Regression procedures:\n",
    "1. Data preparation\n",
    "2. Cross-entropy (Loss function)\n",
    "3. Batch Gradient Descent function\n",
    "4. Mean error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Daily Time Spent on Site</th><th>Age</th><th>Area Income</th><th>Daily Internet Usage</th><th>Ad Topic Line</th></tr><tr><th></th><th>Float64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>String</th></tr></thead><tbody><p>1,000 rows × 10 columns (omitted printing of 5 columns)</p><tr><th>1</th><td>68.95</td><td>35</td><td>61833.9</td><td>256.09</td><td>Cloned 5thgeneration orchestration</td></tr><tr><th>2</th><td>80.23</td><td>31</td><td>68441.9</td><td>193.77</td><td>Monitored national standardization</td></tr><tr><th>3</th><td>69.47</td><td>26</td><td>59785.9</td><td>236.5</td><td>Organic bottom-line service-desk</td></tr><tr><th>4</th><td>74.15</td><td>29</td><td>54806.2</td><td>245.89</td><td>Triple-buffered reciprocal time-frame</td></tr><tr><th>5</th><td>68.37</td><td>35</td><td>73890.0</td><td>225.58</td><td>Robust logistical utilization</td></tr><tr><th>6</th><td>59.99</td><td>23</td><td>59761.6</td><td>226.74</td><td>Sharable client-driven software</td></tr><tr><th>7</th><td>88.91</td><td>33</td><td>53852.8</td><td>208.36</td><td>Enhanced dedicated support</td></tr><tr><th>8</th><td>66.0</td><td>48</td><td>24593.3</td><td>131.76</td><td>Reactive local challenge</td></tr><tr><th>9</th><td>74.53</td><td>30</td><td>68862.0</td><td>221.51</td><td>Configurable coherent function</td></tr><tr><th>10</th><td>69.88</td><td>20</td><td>55642.3</td><td>183.82</td><td>Mandatory homogeneous architecture</td></tr><tr><th>11</th><td>47.64</td><td>49</td><td>45632.5</td><td>122.02</td><td>Centralized neutral neural-net</td></tr><tr><th>12</th><td>83.07</td><td>37</td><td>62491.0</td><td>230.87</td><td>Team-oriented grid-enabled Local Area Network</td></tr><tr><th>13</th><td>69.57</td><td>48</td><td>51636.9</td><td>113.12</td><td>Centralized content-based focus group</td></tr><tr><th>14</th><td>79.52</td><td>24</td><td>51739.6</td><td>214.23</td><td>Synergistic fresh-thinking array</td></tr><tr><th>15</th><td>42.95</td><td>33</td><td>30976.0</td><td>143.56</td><td>Grass-roots coherent extranet</td></tr><tr><th>16</th><td>63.45</td><td>23</td><td>52182.2</td><td>140.64</td><td>Persistent demand-driven interface</td></tr><tr><th>17</th><td>55.39</td><td>37</td><td>23936.9</td><td>129.41</td><td>Customizable multi-tasking website</td></tr><tr><th>18</th><td>82.03</td><td>41</td><td>71511.1</td><td>187.53</td><td>Intuitive dynamic attitude</td></tr><tr><th>19</th><td>54.7</td><td>36</td><td>31087.5</td><td>118.39</td><td>Grass-roots solution-oriented conglomeration</td></tr><tr><th>20</th><td>74.58</td><td>40</td><td>23821.7</td><td>135.51</td><td>Advanced 24/7 productivity</td></tr><tr><th>21</th><td>77.22</td><td>30</td><td>64802.3</td><td>224.44</td><td>Object-based reciprocal knowledgebase</td></tr><tr><th>22</th><td>84.59</td><td>35</td><td>60015.6</td><td>226.54</td><td>Streamlined non-volatile analyzer</td></tr><tr><th>23</th><td>41.49</td><td>52</td><td>32635.7</td><td>164.83</td><td>Mandatory disintermediate utilization</td></tr><tr><th>24</th><td>87.29</td><td>36</td><td>61628.7</td><td>209.93</td><td>Future-proofed methodical protocol</td></tr><tr><th>25</th><td>41.39</td><td>41</td><td>68962.3</td><td>167.22</td><td>Exclusive neutral parallelism</td></tr><tr><th>26</th><td>78.74</td><td>28</td><td>64828.0</td><td>204.79</td><td>Public-key foreground groupware</td></tr><tr><th>27</th><td>48.53</td><td>28</td><td>38067.1</td><td>134.14</td><td>Ameliorated client-driven forecast</td></tr><tr><th>28</th><td>51.95</td><td>52</td><td>58295.8</td><td>129.23</td><td>Monitored systematic hierarchy</td></tr><tr><th>29</th><td>70.2</td><td>34</td><td>32708.9</td><td>119.2</td><td>Open-architected impactful productivity</td></tr><tr><th>30</th><td>76.02</td><td>22</td><td>46180.0</td><td>209.82</td><td>Business-focused value-added definition</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& Daily Time Spent on Site & Age & Area Income & Daily Internet Usage & Ad Topic Line & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Int64 & Float64 & Float64 & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & 68.95 & 35 & 61833.9 & 256.09 & Cloned 5thgeneration orchestration & $\\dots$ \\\\\n",
       "\t2 & 80.23 & 31 & 68441.9 & 193.77 & Monitored national standardization & $\\dots$ \\\\\n",
       "\t3 & 69.47 & 26 & 59785.9 & 236.5 & Organic bottom-line service-desk & $\\dots$ \\\\\n",
       "\t4 & 74.15 & 29 & 54806.2 & 245.89 & Triple-buffered reciprocal time-frame & $\\dots$ \\\\\n",
       "\t5 & 68.37 & 35 & 73890.0 & 225.58 & Robust logistical utilization & $\\dots$ \\\\\n",
       "\t6 & 59.99 & 23 & 59761.6 & 226.74 & Sharable client-driven software & $\\dots$ \\\\\n",
       "\t7 & 88.91 & 33 & 53852.8 & 208.36 & Enhanced dedicated support & $\\dots$ \\\\\n",
       "\t8 & 66.0 & 48 & 24593.3 & 131.76 & Reactive local challenge & $\\dots$ \\\\\n",
       "\t9 & 74.53 & 30 & 68862.0 & 221.51 & Configurable coherent function & $\\dots$ \\\\\n",
       "\t10 & 69.88 & 20 & 55642.3 & 183.82 & Mandatory homogeneous architecture & $\\dots$ \\\\\n",
       "\t11 & 47.64 & 49 & 45632.5 & 122.02 & Centralized neutral neural-net & $\\dots$ \\\\\n",
       "\t12 & 83.07 & 37 & 62491.0 & 230.87 & Team-oriented grid-enabled Local Area Network & $\\dots$ \\\\\n",
       "\t13 & 69.57 & 48 & 51636.9 & 113.12 & Centralized content-based focus group & $\\dots$ \\\\\n",
       "\t14 & 79.52 & 24 & 51739.6 & 214.23 & Synergistic fresh-thinking array & $\\dots$ \\\\\n",
       "\t15 & 42.95 & 33 & 30976.0 & 143.56 & Grass-roots coherent extranet & $\\dots$ \\\\\n",
       "\t16 & 63.45 & 23 & 52182.2 & 140.64 & Persistent demand-driven interface & $\\dots$ \\\\\n",
       "\t17 & 55.39 & 37 & 23936.9 & 129.41 & Customizable multi-tasking website & $\\dots$ \\\\\n",
       "\t18 & 82.03 & 41 & 71511.1 & 187.53 & Intuitive dynamic attitude & $\\dots$ \\\\\n",
       "\t19 & 54.7 & 36 & 31087.5 & 118.39 & Grass-roots solution-oriented conglomeration & $\\dots$ \\\\\n",
       "\t20 & 74.58 & 40 & 23821.7 & 135.51 & Advanced 24/7 productivity & $\\dots$ \\\\\n",
       "\t21 & 77.22 & 30 & 64802.3 & 224.44 & Object-based reciprocal knowledgebase & $\\dots$ \\\\\n",
       "\t22 & 84.59 & 35 & 60015.6 & 226.54 & Streamlined non-volatile analyzer & $\\dots$ \\\\\n",
       "\t23 & 41.49 & 52 & 32635.7 & 164.83 & Mandatory disintermediate utilization & $\\dots$ \\\\\n",
       "\t24 & 87.29 & 36 & 61628.7 & 209.93 & Future-proofed methodical protocol & $\\dots$ \\\\\n",
       "\t25 & 41.39 & 41 & 68962.3 & 167.22 & Exclusive neutral parallelism & $\\dots$ \\\\\n",
       "\t26 & 78.74 & 28 & 64828.0 & 204.79 & Public-key foreground groupware & $\\dots$ \\\\\n",
       "\t27 & 48.53 & 28 & 38067.1 & 134.14 & Ameliorated client-driven forecast & $\\dots$ \\\\\n",
       "\t28 & 51.95 & 52 & 58295.8 & 129.23 & Monitored systematic hierarchy & $\\dots$ \\\\\n",
       "\t29 & 70.2 & 34 & 32708.9 & 119.2 & Open-architected impactful productivity & $\\dots$ \\\\\n",
       "\t30 & 76.02 & 22 & 46180.0 & 209.82 & Business-focused value-added definition & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1000×10 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m Daily Time Spent on Site \u001b[0m\u001b[1m Age   \u001b[0m\u001b[1m Area Income \u001b[0m\u001b[1m Daily Internet Usage \u001b[0m\u001b[1m Ad\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64                  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64              \u001b[0m\u001b[90m St\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │                    68.95     35      61833.9                256.09  Cl ⋯\n",
       "    2 │                    80.23     31      68441.9                193.77  Mo\n",
       "    3 │                    69.47     26      59785.9                236.5   Or\n",
       "    4 │                    74.15     29      54806.2                245.89  Tr\n",
       "    5 │                    68.37     35      73890.0                225.58  Ro ⋯\n",
       "    6 │                    59.99     23      59761.6                226.74  Sh\n",
       "    7 │                    88.91     33      53852.8                208.36  En\n",
       "    8 │                    66.0      48      24593.3                131.76  Re\n",
       "    9 │                    74.53     30      68862.0                221.51  Co ⋯\n",
       "   10 │                    69.88     20      55642.3                183.82  Ma\n",
       "   11 │                    47.64     49      45632.5                122.02  Ce\n",
       "  ⋮   │            ⋮                ⋮         ⋮                ⋮               ⋱\n",
       "  991 │                    35.79     44      33813.1                165.62  En\n",
       "  992 │                    38.96     38      36497.2                140.67  Ve ⋯\n",
       "  993 │                    69.17     40      66193.8                123.62  Ex\n",
       "  994 │                    64.2      27      66201.0                227.63  Ph\n",
       "  995 │                    43.7      28      63127.0                173.01  Fr\n",
       "  996 │                    72.97     30      71384.6                208.58  Fu ⋯\n",
       "  997 │                    51.3      45      67782.2                134.42  Gr\n",
       "  998 │                    51.63     51      42415.7                120.37  Ex\n",
       "  999 │                    55.55     19      41920.8                187.95  Pr\n",
       " 1000 │                    45.01     26      29875.8                178.35  Vi ⋯\n",
       "\u001b[36m                                                  6 columns and 979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"internet.csv\", DataFrame)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×10 Array{Any,2}:\n",
       " 68.95  35  61833.9  256.09  …  \"3/27/2016 0:53\"   0\n",
       " 80.23  31  68441.9  193.77     \"4/4/2016 1:39\"    0\n",
       " 69.47  26  59785.9  236.5      \"3/13/2016 20:35\"  0\n",
       " 74.15  29  54806.2  245.89     \"1/10/2016 2:31\"   0\n",
       " 68.37  35  73890.0  225.58     \"6/3/2016 3:36\"    0\n",
       " 59.99  23  59761.6  226.74  …  \"5/19/2016 14:30\"  0\n",
       " 88.91  33  53852.8  208.36     \"1/28/2016 20:59\"  0\n",
       " 66.0   48  24593.3  131.76     \"3/7/2016 1:40\"    1\n",
       " 74.53  30  68862.0  221.51     \"4/18/2016 9:33\"   0\n",
       " 69.88  20  55642.3  183.82     \"7/11/2016 1:42\"   0\n",
       " 47.64  49  45632.5  122.02  …  \"3/16/2016 20:19\"  1\n",
       " 83.07  37  62491.0  230.87     \"5/8/2016 8:10\"    0\n",
       " 69.57  48  51636.9  113.12     \"6/3/2016 1:14\"    1\n",
       "  ⋮                          ⋱                     \n",
       " 89.71  48  51501.4  204.4      \"2/17/2016 7:00\"   0\n",
       " 70.96  31  55187.8  256.4      \"6/26/2016 7:01\"   0\n",
       " 35.79  44  33813.1  165.62  …  \"4/20/2016 13:36\"  1\n",
       " 38.96  38  36497.2  140.67     \"7/21/2016 16:02\"  1\n",
       " 69.17  40  66193.8  123.62     \"3/6/2016 11:36\"   1\n",
       " 64.2   27  66201.0  227.63     \"2/11/2016 23:45\"  0\n",
       " 43.7   28  63127.0  173.01     \"4/4/2016 3:57\"    1\n",
       " 72.97  30  71384.6  208.58  …  \"2/11/2016 21:49\"  1\n",
       " 51.3   45  67782.2  134.42     \"4/22/2016 2:07\"   1\n",
       " 51.63  51  42415.7  120.37     \"2/1/2016 17:24\"   1\n",
       " 55.55  19  41920.8  187.95     \"3/24/2016 2:35\"   0\n",
       " 45.01  26  29875.8  178.35     \"6/3/2016 21:43\"   1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to matrix\n",
    "convert(Matrix, data[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Array{Int64,1}:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " ⋮\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign values for x and y\n",
    "x_data = [[x[1], x[2]] for x in zip(data[:,1], data.Age)]\n",
    "y_data = [x for x in data[:,10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-entropy (Lossfunction)\n",
    "This function comes from information theory where the goal is to computes the difference between two probability distribution functions.\n",
    "\n",
    "$L_{CE}(\\hat{y}^{i},y^{i}) = -[y^{i}*log\\hat{y}^{i} + (1- y^{i})*log(1-\\hat{y}^{i})]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Loss function\n",
    "\n",
    "$Cost(w,b) = \\frac{1}{N} * \\sum\\limits _{i=1} ^{N}L_{CE}(\\hat{y}^{i},y^{i}) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Cost(w,b) = \\frac{1}{N} * \\sum\\limits _{i=1} ^{N}L_{CE}(\\hat{y}^{i},y^{i}) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ(x) = 1/(1+exp(-x))\n",
    "\n",
    "function cross_entropy_loss(x, y, w, b)\n",
    "    return -y*log(σ(w'x + b)) -(1-y)*log(1 - σ(w'x+b))\n",
    "end\n",
    "\n",
    "function average_loss(features, labels, w, b)\n",
    "    N = length(features)\n",
    "    return (1/N)*sum([cross_entropy_loss(features[i], labels[i], w, b) for i = 1:N])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Gradient Descent function\n",
    "\n",
    "$\\frac{\\partial L_{CE}(w,b)}{\\partial b} = \\frac{1}{N} * \\sum\\limits _{i=1} ^{N} \\frac{\\partial L_{CE}(w,b, \\hat{x}^{i})}{\\partial b} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features, labels, w, b, α)\n",
    "    \n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    \n",
    "    N = length(features)\n",
    "    \n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i]+b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i]+b) - labels[i])\n",
    "    end\n",
    "    \n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    \n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial cost is: 0.6931471805599448\n",
      "The new cost is: 0.68929742452507\n",
      "The new cost is: 0.685902148554632\n",
      "The new cost is: 0.682845301153201\n",
      "The new cost is: 0.6800414995518517\n"
     ]
    }
   ],
   "source": [
    "w = [0.0, 0.0]\n",
    "b = 0.0\n",
    "println(\"The initial cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_loss(x_data, y_data, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_batch_gradient_descent(features, labels, w, b, α, epochs)\n",
    "    \n",
    "    for i = 1:epochs\n",
    "        \n",
    "        w, b = batch_gradient_descent(features, labels, w, b, α)\n",
    "        \n",
    "        if i == 1\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end        \n",
    "        \n",
    "        if i == 10000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "\n",
    "        if i == 100000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100000\n",
    "            println(\"Epoch \", i, \" with loss: \", average_loss(x_data, y_data, w, b))\n",
    "        end  \n",
    "    end\n",
    "    \n",
    "    return w,b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.6663716486734741\n",
      "Epoch 100 with loss: 0.3304944524857512\n",
      "Epoch 1000 with loss: 0.3082781858351418\n",
      "Epoch 10000 with loss: 0.3066952740428512\n",
      "Epoch 100000 with loss: 0.293757141589279\n",
      "Epoch 100000 with loss: 0.293757141589279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.12446326645856375, 0.19863923078348777], 1.2123632358592102)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [0.0, 0.0]\n",
    "b = 0.0\n",
    "\n",
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: NaN\n",
      "Epoch 100 with loss: 0.44026001501689976\n",
      "Epoch 1000 with loss: 0.287222512108937\n",
      "Epoch 10000 with loss: 0.28640423203607124\n",
      "Epoch 100000 with loss: 0.2796755545865263\n",
      "Epoch 100000 with loss: 0.2796755545865263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1367734667551638, 0.18051984307320526], 2.713377601038628)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = randn(2)\n",
    "b = randn(1)[1]\n",
    "\n",
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.279675492180302\n",
      "Epoch 100 with loss: 0.2796693151527702\n",
      "Epoch 1000 with loss: 0.27961326815659965\n",
      "Epoch 10000 with loss: 0.27906333001045586\n",
      "Epoch 100000 with loss: 0.27448224573627905\n",
      "Epoch 100000 with loss: 0.27448224573627905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.14326192319833103, 0.17300053648367972], 3.4328939167412384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2744822029066414\n",
      "Epoch 100 with loss: 0.2744779635529041\n",
      "Epoch 1000 with loss: 0.2744394947498569\n",
      "Epoch 10000 with loss: 0.2740617252972232\n",
      "Epoch 100000 with loss: 0.2708905627848586\n",
      "Epoch 100000 with loss: 0.2708905627848586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1489324445456075, 0.16729043428188786], 4.031337779861745)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2708905329121075\n",
      "Epoch 100 with loss: 0.27088757603118907\n",
      "Epoch 1000 with loss: 0.2708607425902135\n",
      "Epoch 10000 with loss: 0.27059703411499403\n",
      "Epoch 100000 with loss: 0.26836777989604754\n",
      "Epoch 100000 with loss: 0.26836777989604754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1538680679083046, 0.1628671615468941], 4.532943338968981)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2683677587534985\n",
      "Epoch 100 with loss: 0.26836566599581146\n",
      "Epoch 1000 with loss: 0.26834667309564014\n",
      "Epoch 10000 with loss: 0.26815989244620375\n",
      "Epoch 100000 with loss: 0.2665711351819897\n",
      "Epoch 100000 with loss: 0.2665711351819897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.15815751892688973, 0.15938002994837308], 4.956287736032649)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.26657112002446437\n",
      "Epoch 100 with loss: 0.26656961967472415\n",
      "Epoch 1000 with loss: 0.26655600237973576\n",
      "Epoch 10000 with loss: 0.26642200792426746\n",
      "Epoch 100000 with loss: 0.26527608970416344\n",
      "Epoch 100000 with loss: 0.26527608970416344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1618849515164855, 0.15658868922940739], 5.315738002246925)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.2652760787153867\n",
      "Epoch 100 with loss: 0.26527499099867\n",
      "Epoch 1000 with loss: 0.2652651182834484\n",
      "Epoch 10000 with loss: 0.2651679211865382\n",
      "Epoch 100000 with loss: 0.2643328129928623\n",
      "Epoch 100000 with loss: 0.2643328129928623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.1651260397063733, 0.1543247758130958], 5.622529837741352)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.26433280494921957\n",
      "Epoch 100 with loss: 0.2643320087510649\n",
      "Epoch 1000 with loss: 0.2643247816967789\n",
      "Epoch 10000 with loss: 0.2642536000532785\n",
      "Epoch 100000 with loss: 0.263639555439636\n",
      "Epoch 100000 with loss: 0.263639555439636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.16794706706386583, 0.15246780826940348], 5.885553512642443)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.000001, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mean error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(x, y, w, b)\n",
    "    if σ(w'x+b) >= 0.5\n",
    "        return 1\n",
    "    else\n",
    "        return 0       \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error: 0.098\n"
     ]
    }
   ],
   "source": [
    "mean_error = 0.0\n",
    "for i = 1:length(x_data)\n",
    "    mean_error += (predict(x_data[i], y_data[i], w, b) - y_data[i])^2\n",
    "end\n",
    "\n",
    "println(\"The average error: \", mean_error/length(x_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
